<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Words from Shane</title><link>https://shane.ai/posts/</link><description>Recent content in Posts on Words from Shane</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 28 Dec 2022 14:35:59 -0800</lastBuildDate><atom:link href="https://shane.ai/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>Load Testing Tips</title><link>https://shane.ai/posts/load-testing-tips/</link><pubDate>Wed, 28 Dec 2022 14:35:59 -0800</pubDate><guid>https://shane.ai/posts/load-testing-tips/</guid><description>Load testing tips Over a decade plus of getting retailers ready for a smooth Black Friday I&amp;rsquo;ve collected a few tips, tricks, and stories related to keeping busy applications online during big events.
In fact there&amp;rsquo;s one simple (not easy!) trick to it: the best way to ensure your website can handle a big event is to have your website handle a big event. That may seem like a tautology, but it&amp;rsquo;s where this post starts and it&amp;rsquo;s where it ends.</description><content>&lt;h1 id="load-testing-tips">Load testing tips&lt;/h1>
&lt;p>Over a decade plus of getting retailers ready for a smooth Black Friday I&amp;rsquo;ve collected a few tips, tricks, and stories
related to keeping busy applications online during big events.&lt;/p>
&lt;p>In fact there&amp;rsquo;s one simple (not easy!) trick to it: the best way to ensure your website can handle a big
event is to have your website handle a big event. That may seem like a tautology, but it&amp;rsquo;s where this post
starts and it&amp;rsquo;s where it ends.&lt;/p>
&lt;h2 id="background">Background&lt;/h2>
&lt;p>AKA why should you care what I have to say? The short answer is I&amp;rsquo;ve spent alot of time doing this for
everyone from Walmart to Google and that&amp;rsquo;s left me with a bunch of fun war stories I can package up as &amp;ldquo;best practices&amp;rdquo;. Odds
are some of the edge cases I&amp;rsquo;ve ran into will be something you&amp;rsquo;ll run into too and maybe if we&amp;rsquo;re lucky I can
save you an outage.&lt;/p>
&lt;h2 id="how-not-to-load-test">How not to load test&lt;/h2>
&lt;p>Load testing seems simple enough, but it&amp;rsquo;s a fractal of emergent complexity. To paraphrase the old saying about
backups: &amp;ldquo;customers don&amp;rsquo;t care about load tests, they care about the application working when they need it&amp;rdquo;. It&amp;rsquo;s surprisingly
easy to create load tests that give results that bear no relation to the user experience. I should know because
I&amp;rsquo;ve written my share of them.&lt;/p>
&lt;p>Here&amp;rsquo;s an example of a basic load test. Despite all the flaws we&amp;rsquo;ll discuss, I often start here due to ease of use.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>$ wrk -t1 -c &lt;span style="color:#ae81ff">10&lt;/span> -d10 &lt;span style="color:#e6db74">&amp;#39;https://example.com/&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Running 10s test @ https://example.com/
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ae81ff">1&lt;/span> threads and &lt;span style="color:#ae81ff">10&lt;/span> connections
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Thread Stats Avg Stdev Max +/- Stdev
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Latency 25.00ms 13.04ms 230.48ms 92.26%
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Req/Sec 135.68 49.04 202.00 78.79%
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ae81ff">1341&lt;/span> requests in 10.00s, 644.14KB read
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Non-2xx or 3xx responses: &lt;span style="color:#ae81ff">1341&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Requests/sec: 134.08
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Transfer/sec: 64.41KB
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;a href="https://github.com/wg/wrk">wrk&lt;/a> is a reasonably good tool for generating HTTP request load. The above code uses one
thread and 10 connections to make requests for 10 seconds. I&amp;rsquo;m going to use this as a springboard into what can go wrong.&lt;/p>
&lt;h3 id="caching">Caching&lt;/h3>
&lt;p>If your application has caching and your load test just hammers one single url repeatedly, it&amp;rsquo;s very likely you could get
artificially high cache hit rates and low latency. For an ecommerce application there&amp;rsquo;s often a very long tail of low traffic
product page requests that don&amp;rsquo;t have a very high cache hit rate. It&amp;rsquo;s not unusual to have a 10x difference in performance
for cached vs uncached responses.&lt;/p>
&lt;p>There are various ways to fix this, but they depend on the application and CDN configuration. It&amp;rsquo;s possible to
add cache-control headers to request the server disable a cache (in fact when you Ctrl-F5 refresh this is what your browser does). It&amp;rsquo;s also possible to add cache busting query strings via timestamp.&lt;/p>
&lt;h3 id="compression">Compression&lt;/h3>
&lt;p>Doing compression wrong is another very frequent mistake. Most customers who interact with your web app using a browser support gzip compression (some of them support brotli). Overall for text payloads like HTML/JSON/JS/CSS gzip compression provides huge bandwidth savings. In addition many CDNs either store responses gzipped to save space, or they store gzipped and non-gzipped responses separately (the relevant part of the HTTP spec involves the Vary header &lt;code>Vary: Accept-Encoding&lt;/code>). Compression can throw off your test results in 2 ways.&lt;/p>
&lt;ol>
&lt;li>You might be bandwidth limited during your tests if you forget to use a client that supports compression.&lt;/li>
&lt;li>I&amp;rsquo;ve seen people get poor performance when using clients that don&amp;rsquo;t support compression with a CDN that stores a single canonical gzip compressed copy of content, resulting in constant gunzipping on the fly.&lt;/li>
&lt;/ol>
&lt;p>Avoiding this is generally as simple as ensuring your client sends the &lt;code>Accept-Encoding: gzip&lt;/code> header. For more advanced tests you might want to simulate multiple clients so that you can test gzip and brotli and ensure that cache forking on the 2 methods isn&amp;rsquo;t reducing your overall cache hit rate.&lt;/p>
&lt;h3 id="connection-management">Connection management&lt;/h3>
&lt;p>Connection management is &amp;ldquo;how requests get mapped onto underlying transports&amp;rdquo;. Are you using HTTP/1.1? HTTP/2? HTTP/3? With or without TLS? Keepalive? The answer affects how much load you&amp;rsquo;ll be able to generate on the applications vs the infrastructure between your client and the app. Here&amp;rsquo;s the bare minimum you need to know:&lt;/p>
&lt;h4 id="http-protocol-versions">HTTP Protocol versions&lt;/h4>
&lt;p>In the early days of HTTP servers closed the TCP connection to indicate a response was complete. One connection served one request. The problem was that TCP connections can be expensive to setup See: &lt;a href="https://developer.mozilla.org/en-US/docs/Glossary/TCP_handshake">TCP Handshake&lt;/a>. Developers quickly came up with a way to reuse connections by sending the &lt;code>Content-Length&lt;/code> response header which allowed a client to know when a response was done. Then a new request could be sent on the connection if both the server and client had sent a &lt;code>keep-alive&lt;/code> header. When combined with connection pooling this allowed clients to have several concurrent requests multiplexed onto several TCP connections. This was standardized in HTTP/1.1, along with some fixes for streaming content.&lt;/p>
&lt;p>Until recently HTTP/1.1 was the protocol used by default when a CDN connected to your website origin, although as of writing this blog I see that both Google &lt;a href="https://cloud.google.com/media-cdn/docs/origins">Media CDN&lt;/a> and &lt;a href="https://developers.cloudflare.com/cache/how-to/enable-http2-to-origin/">Cloudflare CDN&lt;/a> support HTTP/2 to origin as well although it appears some other popular CDNs such as Akamai &lt;a href="https://myakamai.force.com/customers/s/question/0D54R00007GkHvvSAF/does-akamai-support-http2-between-edge-to-origin?language=en_US">do not&lt;/a>. HTTP/2 addresses some of the problems of HTTP/1.1 by allowing multiple request/responses to be sent concurrently over the same connection. Although you could send multiple requests with HTTP/1.1 you generally had to wait for a response before you sent a new request (ignoring &lt;a href="https://en.wikipedia.org/wiki/HTTP_pipelining">pipelining&lt;/a> which is rarely used). This leads to a problem called &lt;a href="https://en.wikipedia.org/wiki/Head-of-line_blocking">head of line blocking&lt;/a> wherein delays in processing a single request will hold up all the others. There are a bunch of other enhancements in HTTP/2 but they are mostly out of scope for this article. The biggest change is that HTTP/2 reduces the need for multiple connections and generally runs over TLS (The TCP only version of HTTP/2 is not as well supported). However it can still suffer from head of line blocking because TCP delivers packets in order so one dropped packet means everything on the multiplexed connection stalls. There&amp;rsquo;s also HTTP/3 which is built on top of UDP which enables &lt;a href="https://calendar.perfplanet.com/2020/head-of-line-blocking-in-quic-and-http-3-the-details/#sec_http3">HTTP/3 to solve&lt;/a> the head of line blocking problem.&lt;/p>
&lt;h4 id="connection-configuration-tips">Connection configuration tips&lt;/h4>
&lt;p>Here&amp;rsquo;s what this means for performance testing:&lt;/p>
&lt;p>If you don&amp;rsquo;t use keepalive you&amp;rsquo;ll create tons of TCP connections. That&amp;rsquo;s good if you want to test your load balancer and find out how well you&amp;rsquo;ve tuned your TCP stack on the load generating machines. In all likelyhood you will quickly exhaust your ephemeral ports if you do a naive test w/o keepalive. Personally I&amp;rsquo;d likely use HTTP/1.1 over TLS with keepalive for most application load testing. Ideally you want to use what your customers use which is usually HTTP/2, but HTTP/2 support in load testing tools can be spotty, and depending on your CDN/Load Balancer setup odds are you&amp;rsquo;re speaking HTTP/1.1 to origin anyways.&lt;/p>
&lt;p>To put it in code, here&amp;rsquo;s a good starting point:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># wrk defaults to keepalive&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>wrk -c $CONNECTION_COUNT -t $THREADS -d $DURATION -H &lt;span style="color:#e6db74">&amp;#39;Accept-Encoding: gzip&amp;#39;&lt;/span> &lt;span style="color:#e6db74">&amp;#39;https://website/&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Like everything else in engineering, there are tradeoffs. The single best load test you could do would be to have agents everywhere your customers are making connections and requests exactly like your customers. There are some ways to do that, but just as normal software testing involves running fast unit tests more frequently and slower integration tests less often, a good load testing strategy often involves frequent tests with something like &lt;code>wrk&lt;/code> and less frequent high fidelity tests accross multiple regions. Most of the time I want to use just a few connections to hammer the application, but occasionally I want to make sure the TCP side of the stack is up to snuff.&lt;/p>
&lt;h3 id="unrealistic-client-locations">Unrealistic client locations&lt;/h3>
&lt;p>This is a really broad one, but what happens is that generally your customers are all over your country or possibly all over the world. Quite often a load test is being run from a single region. This can distort results in all sorts of fun ways.&lt;/p>
&lt;h4 id="cdn-pop-overload">CDN Pop Overload&lt;/h4>
&lt;p>Your CDN likely routes customers to the closest PoP (Point of Presence). Your load test could overload a single PoP and leave the rest of the CDN and your datacenters with no traffic. Many engineers accidentally load test CDN hot spot mitigation paths, not their app.&lt;/p>
&lt;h4 id="unbalanced-network-traffic">Unbalanced network traffic&lt;/h4>
&lt;p>It is very possible that if all load is coming from a single region, parts along the way can get overloaded. As an example many load balancers doing some form of &lt;a href="https://en.wikipedia.org/wiki/Equal-cost_multi-path_routing">ECMP&lt;/a> will direct traffic based on some hash of connection information which can result in hot spots if there aren&amp;rsquo;t enough connections. Similarly intermediate routers can be overloaded. For that reason I recommend using multiple load generating agents.&lt;/p>
&lt;p>From a practical perspective I like to use something like &lt;a href="https://cloud.google.com/run">Cloud Run&lt;/a> because it scales to 0 based on traffic so it&amp;rsquo;s pretty cheap to deploy a container to every single region.&lt;/p>
&lt;h3 id="unrealistic-traffic">Unrealistic traffic&lt;/h3>
&lt;p>Here&amp;rsquo;s a very common story at large retailers. Someone runs a load test. The app passes with flying colors. Organic traffic begins to ramp up. The website crashes. What happened?&lt;/p>
&lt;p>Well it turns out naive load tests often fail to exercise critical components. Here&amp;rsquo;s just a handfull of ways I&amp;rsquo;ve seen this happen:&lt;/p>
&lt;p>The load test was detected as a bot and all those super fast 200 responses were captcha pages. Nobody bothered to verify that the page under test was returning the correct content.&lt;/p>
&lt;p>The load test pulled down a product page (eg &lt;code>https://example.com/product/123&lt;/code>) but since this is a SPA (Single Page App) all the important API calls happened via &lt;code>fetch&lt;/code>/&lt;code>XHR&lt;/code> and so all the load test really did was pull down an empty shell of a page.&lt;/p>
&lt;p>The load test pulled down all the HTML, but none of the associated resources such as images/css/javascript etc. More than once in my career I&amp;rsquo;ve seen developers put timestamp cache busters on their static content, only to cause an outage when they deploy and every single request from customers is a cache miss (eg &lt;code>https://example.com/static/image.jpg?buster=123123.123123&lt;/code>).&lt;/p>
&lt;h2 id="how-to-create-load-tests-that-give-you-confidence-your-webapp-will-scale">How to create load tests that give you confidence your webapp will scale&lt;/h2>
&lt;p>What you want is to simulate a bunch of real customers doing a bunch of realistic things on your webapp. Real customers come from different locations. They use different browsers. They look at different products. They do things like search/login/add to chart/checkout/etc. They execute javascript and download images. They use browsers that &lt;a href="https://caniuse.com/http2">support HTTP/2&lt;/a> or &lt;a href="https://caniuse.com/http3">HTTP/3&lt;/a>. Of course running a load test with chrome is alot more resource intensive than running a load test with &lt;code>wrk&lt;/code>, just like an end to end integration test is more expensive than a unit test.&lt;/p>
&lt;p>I recommend you start out with benchmarks alongside your repo&amp;rsquo;s unit tests. These should be ran frequently and tracked in your metrics system. For every release you should know how the behaviour of core endpoints like &lt;code>GET /resource/foo&lt;/code> behaves under load, possibly with mocked datastore or API dependencies. Problems found here are cheapest to fix. In Go this looks like something using the &lt;a href="https://pkg.go.dev/net/http/httptest">httptest&lt;/a> package and their &lt;a href="https://pkg.go.dev/testing#hdr-Benchmarks">Benchmark&lt;/a> package. Now it&amp;rsquo;s often the case that the team writing load tests is not the app development team, but SRE best practices show that cross functional teams co-developing features results in fewer big issues during launch.&lt;/p>
&lt;p>The next layer up is &amp;ldquo;simple&amp;rdquo; scripted CLI load tests. I like &lt;code>wrk&lt;/code> with lua scripting which can do a pretty good job of hitting a bunch of random urls quickly and defeating caching if needed. It doesn&amp;rsquo;t support http/2 but &lt;a href="https://github.com/tsliwowicz/go-wrk">go-wrk&lt;/a> does. Properly configured with compression support this is a great workhorse for individual teams to test their critical endpoints. You can also do more complicated tests such as requesting a resource and then dependent resources but that can take alot of work and knowledge of the application to capture the right requests to make. People often use Siege here or even Apache Jmeter.&lt;/p>
&lt;p>Finally for full scale high fidelity load tests there are relatively few tools out there for browser based load testing. Unfortunately the automation frameworks out there such as selenium can be fragile and have lots of overhead and so &lt;a href="https://www.selenium.dev/documentation/test_practices/discouraged/performance_testing/">they discourage using their libraries for load testing&lt;/a>.&lt;/p>
&lt;p>There are essentially three approaches I like to use.&lt;/p>
&lt;p>The first one feels like cheating but after several years preparing Walmart for Black Friday I can attest to it&amp;rsquo;s unreasonable effectiveness. Before your big event (such as Black Friday) hold some sort of flash sale/small event. For example one year there was a highly anticipated low-quantity device that had just been released. My company stocked a few on their website and sent out an email marketing blast and instantly generated the best load test money can buy as customers flocked to the website to get a good deal. We of course had a minor outage and then had time to optimize and fix before Black Friday/Cyber Monday. If you can run some sort of test marketing event before the big event you absolutely should.&lt;/p>
&lt;p>On the more technical side: it&amp;rsquo;s possible to record a real customer interaction and export HAR (http archive) files. Those can be &lt;a href="https://www.flood.io/blog/convert-har-files-to-jmeter-test-plans">imported into something like jmeter&lt;/a>, or you can write your own converter. I haven&amp;rsquo;t tried this approach yet.&lt;/p>
&lt;p>My preferred approach at the moment is to use headless chrome on cloud run to generate load from multiple regions. With a little scripting in &lt;a href="https://chromedriver.chromium.org/home">chromedriver&lt;/a> it&amp;rsquo;s possible to load a bunch of pages, take screenshots, and export all the timing metrics for later processing. &lt;a href="https://cloud.google.com/workflows">Cloud Workflows&lt;/a> orchestrate the process and take care of ramping up traffic and collecting summary statistics. I&amp;rsquo;m working on open sourcing my workflows/containers here to allow others to easily spin up real-browser load tests. Stay tuned.&lt;/p></content></item></channel></rss>